# Etapas do Projeto (Cronograma de 4 a 6 Semanas)

## ğŸ—‚ï¸ Semana 1 â€“ Planejamento e Coleta de Dados

Objetivo: Definir a base do projeto e iniciar o Data Lake.
- Estruturar o repositÃ³rio no GitHub (pastas, README, versionamento).
- Mapear fontes de dados relevantes (APIs pÃºblicas e datasets sobre restaurantes, consumo e desperdÃ­cio).

 - Conectar e coletar dados via R (httr, jsonlite, tidyverse).

- Armazenar dados brutos no Data Lake local (formato CSV/Parquet).

- Criar documentaÃ§Ã£o inicial sobre o fluxo de coleta.

ğŸ“˜ Resultado esperado: primeiros datasets organizados e centralizados em um ambiente de Data Lake.

## ğŸ§® Semana 2 â€“ Tratamento e Modelagem de Dados

Objetivo: Limpar, padronizar e preparar dados para os Data Marts.

- Tratar valores nulos, duplicados e inconsistÃªncias com dplyr e tidyr.

- Normalizar unidades e padronizar colunas (ex: datas, categorias de produtos).

- Implementar lÃ³gica de extraÃ§Ã£o de mÃ©tricas Ãºteis (ex: desperdÃ­cio diÃ¡rio, ticket mÃ©dio).

- Criar tabelas derivadas para Data Mart de Vendas e Data Mart de DesperdÃ­cio.

- Salvar dados transformados em formato pronto para anÃ¡lise (CSV/SQLite).

ğŸ“˜ Resultado esperado: dados limpos e prontos para uso analÃ­tico.

## ğŸ¤– Semana 3 â€“ Desenvolvimento do Modelo Preditivo

Objetivo: Criar pipeline de machine learning integrada ao fluxo de dados.

- Definir variÃ¡veis preditoras e alvo (ex: volume de desperdÃ­cio, probabilidade de sobra).

- Separar dados em treino/teste com caret ou tidymodels.

- Implementar um modelo simples (ex: regressÃ£o linear ou Ã¡rvore de decisÃ£o).

 - Automatizar a atualizaÃ§Ã£o de previsÃµes com scripts R.

 - Criar mÃ©tricas de avaliaÃ§Ã£o (MAE, RMSE, acurÃ¡cia).

ğŸ“˜ Resultado esperado: pipeline inicial funcional com previsÃµes bÃ¡sicas.

## ğŸ“Š Semana 4 â€“ VisualizaÃ§Ã£o, DocumentaÃ§Ã£o e Ajustes

Objetivo: Consolidar resultados e preparar o projeto para apresentaÃ§Ã£o.

- Criar dashboards analÃ­ticos simples com ggplot2 e shiny (opcional).

- Documentar todas as etapas (README e relatÃ³rios em Markdown).

- Revisar estrutura do repositÃ³rio e boas prÃ¡ticas de cÃ³digo.

- Ajustar parÃ¢metros do modelo e preparar sugestÃµes de melhoria futura.

ğŸ“˜ Resultado esperado: versÃ£o funcional e documentada do projeto.

##ğŸ• ExtensÃ£o opcional (Semanas 5 e 6)

Se houver mais tempo, o foco pode ser:

- Refinar a pipeline para atualizaÃ§Ã£o automÃ¡tica (ex: CRON jobs ou APIs em tempo real).

- Testar outros algoritmos de ML (Random Forest, Gradient Boosting).

Melhorar o front-end de visualizaÃ§Ã£o com Shiny Dashboard ou Flexdashboard.

Integrar armazenamento em banco de dados SQL e modularizar o cÃ³digo.
